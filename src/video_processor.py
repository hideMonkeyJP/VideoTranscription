import os
import argparse
import datetime
import json
import re
import itertools
from moviepy.editor import VideoFileClip
import speech_recognition as sr
from PIL import Image, ImageEnhance, ImageFilter
import pytesseract
import yaml
import cv2
import html
import unicodedata
from collections import Counter
from transformers import pipeline

class VideoProcessor:
    def __init__(self):
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®è¨­å®š
        self.config = {
            'speech_recognition': {
                'whisper_model': 'medium',  # ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º
                'language': 'ja',           # æ—¥æœ¬èª
                'min_confidence': 0.5       # æœ€å°ä¿¡é ¼åº¦
            },
            'ocr': {
                'languages': 'jpn+eng'      # æ—¥æœ¬èªã¨è‹±èªã®OCR
            }
        }
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š
        self.output_dir = 'output'
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)

    def process_video(self, video_path):
        """å‹•ç”»ã‚’å‡¦ç†ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒã‚’æŠ½å‡º"""
        try:
            # 1. éŸ³å£°ã®æŠ½å‡º
            audio_path = self.extract_audio(video_path)
            if not audio_path:
                raise Exception("éŸ³å£°ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ")

            # 2. éŸ³å£°ã®æ–‡å­—èµ·ã“ã—
            transcription = self.transcribe_audio(audio_path)
            if not transcription:
                raise Exception("éŸ³å£°èªè­˜ã«å¤±æ•—ã—ã¾ã—ãŸ")

            # 3. ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®ç”Ÿæˆã¨å‡¦ç†
            screenshots = self.capture_screenshots(video_path)
            if not screenshots:
                raise Exception("ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")

            # 4. ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®OCRå‡¦ç†
            screenshots = self.process_screenshots(screenshots)

            # 5. çµæœã®æ•´å½¢
            result = {
                "video_file": os.path.basename(video_path),
                "transcription": transcription,
                "screenshots": screenshots
            }

            # 6. çµæœã®ä¿å­˜
            self.save_results(result)

            return result

        except Exception as e:
            print(f"ãƒ“ãƒ‡ã‚ªå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def extract_audio(self, video_path):
        """å‹•ç”»ã‹ã‚‰éŸ³å£°ã‚’æŠ½å‡º"""
        try:
            video = VideoFileClip(video_path)
            audio_path = os.path.join(self.output_dir, "temp_audio.wav")
            video.audio.write_audiofile(audio_path)
            return audio_path
        except Exception as e:
            print(f"éŸ³å£°æŠ½å‡ºä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def transcribe_audio(self, audio_path):
        import whisper
        from whisper.utils import get_writer
        
        # Whisperãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
        model = whisper.load_model(self.config['speech_recognition'].get('whisper_model', 'medium'))
        
        # éŸ³å£°èªè­˜ã®å®Ÿè¡Œ
        result = model.transcribe(
            audio_path,
            language=self.config['speech_recognition']['language'],
            temperature=0.2,                # ç¢ºå®šçš„ãªå‡ºåŠ›
            beam_size=3,                    # ç²¾åº¦ã¨é€Ÿåº¦ã®ãƒãƒ©ãƒ³ã‚¹
            best_of=3,                      # å€™è£œæ•°æœ€é©åŒ–
            verbose=False,
            condition_on_previous_text=False,
            compression_ratio_threshold=2.4,# åœ§ç¸®ç‡ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            no_speech_threshold=0.6,        # ç„¡éŸ³æ¤œå‡ºé–¾å€¤
            suppress_tokens=[-1]            # ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³æŠ‘åˆ¶
        )
        
        word_entries = []
        if not result.get('segments'):
            print("è­¦å‘Š: éŸ³å£°èªè­˜çµæœãŒç©ºã§ã™ã€‚éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
            return word_entries
            
        for segment_idx, segment in enumerate(result.get('segments', [])):
            segment_text = segment.get('text', '')
            
            clean_segment_text = re.sub(
                r'[^\wã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¯ï½-ï½šï¼¡-ï¼ºï¼-ï¼™ãƒ»ãƒ¼ã€ã€‚]',
                '',
                segment_text
            ).strip()
            
            if not clean_segment_text:
                print(f"è­¦å‘Š: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ{segment_idx}ã®ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã§ã™")
                continue
            
            if not segment.get('words'):
                print(f"æƒ…å ±: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ{segment_idx}ã®æ–‡å…¨ä½“ã‚’ä½¿ç”¨ã—ã¾ã™")
                word_entries.append({
                    "text": clean_segment_text,
                    "start": round(segment['start'], 2),
                    "end": round(segment['end'], 2),
                    "confidence": round(segment.get('avg_logprob', 0), 2)
                })
                continue
            
            for word_idx, word in enumerate(segment.get('words', [])):
                try:
                    confidence = word.get('probability', 0)
                    if confidence >= self.config['speech_recognition'].get('min_confidence', 0.5):
                        clean_text = re.sub(
                            r'[^\wã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¯ï½-ï½šï¼¡-ï¼ºï¼-ï¼™ãƒ»ãƒ¼ã€ã€‚]',
                            '',
                            word['word']
                        ).strip()
                        
                        if len(clean_text) > 0:
                            word_entries.append({
                                "text": clean_text,
                                "start": round(word['start'], 2),
                                "end": round(word['end'], 2),
                                "confidence": round(confidence, 2)
                            })
                except Exception as e:
                    print(f"ã‚¨ãƒ©ãƒ¼: {segment_idx}-{word_idx} - {str(e)}")
        
        return word_entries

    def capture_screenshots(self, video_path):
        """ãƒ“ãƒ‡ã‚ªã‹ã‚‰ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’ç”Ÿæˆ"""
        try:
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                raise Exception("ãƒ“ãƒ‡ã‚ªãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸ")

            fps = cap.get(cv2.CAP_PROP_FPS)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            duration = total_frames / fps
            
            interval = 10
            screenshots = []
            
            for time in range(0, int(duration), interval):
                frame_number = int(time * fps)
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)
                ret, frame = cap.read()
                
                if ret:
                    screenshot_path = f"screenshot_{time}.jpg"
                    output_path = os.path.join(self.output_dir, screenshot_path)
                    if cv2.imwrite(output_path, frame):
                        print(f"ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’ä¿å­˜: {output_path}")
                        screenshots.append({
                            "timestamp": time,
                            "image_path": output_path,  # ãƒ•ãƒ«ãƒ‘ã‚¹ã‚’ä¿å­˜
                            "text": ""
                        })
                    else:
                        print(f"ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®ä¿å­˜ã«å¤±æ•—: {output_path}")
            
            cap.release()
            return screenshots
            
        except Exception as e:
            print(f"ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    def _calculate_text_quality(self, text):
        """ãƒ†ã‚­ã‚¹ãƒˆã®å“è³ªã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆ0.0 ~ 1.0ï¼‰"""
        if not text or len(text.strip()) < 3:
            return 0.0

        # åŸºæœ¬ã‚¹ã‚³ã‚¢ã®åˆæœŸåŒ–
        score = 1.0

        # 1. æ–‡å­—ç¨®é¡ã®è©•ä¾¡
        chars = Counter(text)
        unique_ratio = len(chars) / len(text)
        score *= min(1.0, unique_ratio * 2)  # æ–‡å­—ã®å¤šæ§˜æ€§ã‚’è©•ä¾¡

        # 2. æ„å‘³ã®ã‚ã‚‹æ–‡å­—ã®å‰²åˆ
        meaningful_chars = sum(1 for c in text if c.isalnum() or 0x3000 <= ord(c) <= 0x9FFF)
        meaningful_ratio = meaningful_chars / len(text)
        score *= meaningful_ratio

        # 3. è¨˜å·ã®å‰²åˆè©•ä¾¡
        symbol_ratio = sum(1 for c in text if not c.isalnum() and not 0x3000 <= ord(c) <= 0x9FFF) / len(text)
        score *= (1.0 - min(1.0, symbol_ratio * 2))

        # 4. ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
        # é€£ç¶šã™ã‚‹åŒã˜æ–‡å­—
        max_repeat = max(len(list(g)) for _, g in itertools.groupby(text))
        if max_repeat > 3:
            score *= 0.5

        # 5. æ—¥æœ¬èªæ–‡å­—ã®è©•ä¾¡
        jp_ratio = sum(1 for c in text if 0x3000 <= ord(c) <= 0x9FFF) / len(text)
        if jp_ratio > 0:
            score *= (1.0 + jp_ratio)  # æ—¥æœ¬èªæ–‡å­—ãŒå«ã¾ã‚Œã‚‹å ´åˆã¯ã‚¹ã‚³ã‚¢ã‚’ä¸Šã’ã‚‹

        # 6. ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆã®è©•ä¾¡
        if text.isascii():
            # æ¯éŸ³ã®å­˜åœ¨ç¢ºèª
            vowel_ratio = sum(1 for c in text.lower() if c in 'aeiou') / len(text)
            if vowel_ratio < 0.1:  # æ¯éŸ³ãŒå°‘ãªã™ãã‚‹å ´åˆ
                score *= 0.5

        return min(1.0, score)

    def process_screenshots(self, screenshots):
        """ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®å‡¦ç†ã¨OCR"""
        for ss in screenshots:
            try:
                # ç”»åƒã®å‰å‡¦ç†ã‚’å¼·åŒ–ï¼ˆãƒ•ãƒ«ãƒ‘ã‚¹ã‚’ä½¿ç”¨ï¼‰
                image = Image.open(ss["image_path"])
                
                # å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
                # 1. ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
                image = image.convert('L')
                
                # 2. ãƒã‚¤ãƒŠãƒªåŒ–ã®ãŸã‚ã®é–¾å€¤ã‚’è‡ªå‹•è¨ˆç®—
                threshold = int(sum(image.histogram()[i] * i for i in range(256)) / sum(image.histogram()))
                
                # 3. ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·èª¿
                enhancer = ImageEnhance.Contrast(image)
                image = enhancer.enhance(2.5)
                
                # 4. ã‚·ãƒ£ãƒ¼ãƒ—ãƒã‚¹å¼·èª¿
                enhancer = ImageEnhance.Sharpness(image)
                image = enhancer.enhance(2.5)
                
                # 5. ãƒã‚¤ã‚ºé™¤å»ï¼ˆãƒ¡ãƒ‡ã‚£ã‚¢ãƒ³ãƒ•ã‚£ãƒ«ã‚¿ï¼‰
                image = image.filter(ImageFilter.MedianFilter(size=3))
                
                # 6. ç”»åƒã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
                if image.size[0] < 1000:  # å°ã•ã™ãã‚‹ç”»åƒã¯æ‹¡å¤§
                    scale = 1000 / image.size[0]
                    new_size = (int(image.size[0] * scale), int(image.size[1] * scale))
                    image = image.resize(new_size, Image.Resampling.LANCZOS)

                # OCRå®Ÿè¡Œï¼ˆè¨­å®šã‚’æœ€é©åŒ–ï¼‰
                text = pytesseract.image_to_string(
                    image,
                    lang=self.config['ocr']['languages'],
                    config='--psm 6 --oem 3 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789ã‚ã„ã†ãˆãŠã‹ããã‘ã“ã•ã—ã™ã›ããŸã¡ã¤ã¦ã¨ãªã«ã¬ã­ã®ã¯ã²ãµã¸ã»ã¾ã¿ã‚€ã‚ã‚‚ã‚„ã‚†ã‚ˆã‚‰ã‚Šã‚‹ã‚Œã‚ã‚ã‚’ã‚“ã‚¢ã‚¤ã‚¦ã‚¨ã‚ªã‚«ã‚­ã‚¯ã‚±ã‚³ã‚µã‚·ã‚¹ã‚»ã‚½ã‚¿ãƒãƒ„ãƒ†ãƒˆãƒŠãƒ‹ãƒŒãƒãƒãƒãƒ’ãƒ•ãƒ˜ãƒ›ãƒãƒŸãƒ ãƒ¡ãƒ¢ãƒ¤ãƒ¦ãƒ¨ãƒ©ãƒªãƒ«ãƒ¬ãƒ­ãƒ¯ãƒ²ãƒ³ã€ã€‚ï¼Œï¼ãƒ»ãƒ¼'
                )

                # ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ–‡å­—ã‚³ãƒ¼ãƒ‰å‡¦ç†
                try:
                    # æ–‡å­—ã‚³ãƒ¼ãƒ‰ã®æ­£è¦åŒ–ã¨ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
                    text = text.encode('utf-8', errors='ignore').decode('utf-8')
                    # Unicodeã®æ­£è¦åŒ–ï¼ˆå…¨è§’ãƒ»åŠè§’ã®çµ±ä¸€ï¼‰
                    text = unicodedata.normalize('NFKC', text)
                    
                    lines = [line.strip() for line in text.split('\n')]
                    cleaned_lines = []
                    for line in lines:
                        if len(line) <= 1:  # ç©ºè¡Œã‚„1æ–‡å­—ã®è¡Œã‚’é™¤å¤–
                            continue
                            
                        # åˆ¶å¾¡æ–‡å­—ã¨ç‰¹æ®Šæ–‡å­—ã‚’é™¤å»
                        line = ''.join(c for c in line if ord(c) >= 32 or c == '\n')
                        
                        # 1. è¡Œã®å‰å‡¦ç†
                        line = line.strip()
                        if len(line) <= 3:  # çŸ­ã™ãã‚‹è¡Œã¯é™¤å¤–
                            continue

                        # 2. ç‰¹æ®Šæ–‡å­—ã¨è¨˜å·ã®å‡¦ç†
                        # ç‰¹æ®Šæ–‡å­—ã‚„è¨˜å·ãŒå¤šã™ãã‚‹è¡Œã‚’é™¤å¤–
                        symbol_count = sum(1 for c in line if not c.isalnum() and not 0x3000 <= ord(c) <= 0x9FFF)
                        if symbol_count > len(line) * 0.2:  # 20%ä»¥ä¸ŠãŒè¨˜å·ã®å ´åˆã¯é™¤å¤–
                            continue

                        # é€£ç¶šã™ã‚‹è¨˜å·ã‚„ç‰¹æ®Šæ–‡å­—ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
                        if re.search(r'[-_@#$%^&*(){}\[\]|;:]{2,}|[O\-â€”]{2,}|[A-Z0-9]{4,}', line):
                            continue

                        # URLã€ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã€ç‰¹æ®Šãªè­˜åˆ¥å­ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
                        if re.search(r'(https?:\/\/|www\.|\/|\[|\]|\(\)|#\d+|[A-Z]+\d+|\d+[A-Z]+)', line):
                            continue

                        # ç‰¹å®šã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã§å§‹ã¾ã‚‹è¡Œã‚’é™¤å¤–
                        if any(line.startswith(prefix) for prefix in ['Â©', 'Â®', 'â„¢', '[]', 'ã€', 'ã€‹', '-O', '@', '#', '*', '=']):
                            continue

                        # 3. ãƒ†ã‚­ã‚¹ãƒˆå“è³ªã®è©³ç´°è©•ä¾¡
                        # æ—¥æœ¬èªæ–‡å­—ã®æ¤œå‡º
                        jp_chars = sum(1 for c in line if 0x3000 <= ord(c) <= 0x9FFF)
                        
                        # æ„å‘³ã®ã‚ã‚‹æ–‡å­—åˆ—ã‹ãƒã‚§ãƒƒã‚¯
                        meaningful_chars = sum(1 for c in line if c.isalnum() or 0x3000 <= ord(c) <= 0x9FFF)
                        if meaningful_chars < len(line) * 0.7:  # 70%ä»¥ä¸ŠãŒæ„å‘³ã®ã‚ã‚‹æ–‡å­—ã§ã‚ã‚‹ã“ã¨
                            continue
                        
                        # æ–‡å­—åˆ—ã®æœ€å°é•·ãƒã‚§ãƒƒã‚¯
                        if len(line) < 5:
                            continue
                            
                        # è¨˜å·ã‚„ç‰¹æ®Šæ–‡å­—ã®é€£ç¶šã‚’ãƒã‚§ãƒƒã‚¯
                        if re.search(r'[-_@#$%^&*(){}\[\]|;:]{2,}|[O\-â€”]{2,}', line):
                            continue
                            
                        # æ–‡å­—ã®å¤šæ§˜æ€§ãƒã‚§ãƒƒã‚¯
                        char_freq = Counter(line)
                        unique_ratio = len(char_freq) / len(line)
                        if unique_ratio < 0.6:  # æ–‡å­—ã®ç¨®é¡ãŒ60%æœªæº€ã¯é™¤å¤–
                            continue
                            
                        # ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆã®ã¿ã®æ–‡å­—åˆ—ã®å ´åˆã®è¿½åŠ ãƒã‚§ãƒƒã‚¯
                        if line.isascii() and line.replace(' ', '').isalpha():
                            # æ¯éŸ³ã®å‰²åˆãƒã‚§ãƒƒã‚¯
                            vowels = sum(1 for c in line.lower() if c in 'aeiou')
                            if vowels / len(line) < 0.15:  # æ¯éŸ³ãŒå°‘ãªã™ãã‚‹å ´åˆã¯é™¤å¤–
                                continue

                        # 4. ãƒ†ã‚­ã‚¹ãƒˆå“è³ªã®ç·åˆè©•ä¾¡
                        quality_score = self._calculate_text_quality(line)
                        if quality_score <= 0.6:  # ã‚ˆã‚Šå³ã—ã„å“è³ªé–¾å€¤
                            continue

                        # 5. è¿½åŠ ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                        # é€£ç¶šã™ã‚‹ç‰¹æ®Šæ–‡å­—ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
                        if re.search(r'[-_@#$%^&*(){}\[\]|;:]+', line):
                            continue
                            
                        # ç„¡æ„å‘³ãªå¤§æ–‡å­—ã®é€£ç¶šã‚’æ¤œå‡º
                        if re.search(r'[A-Z]{4,}', line) and not re.search(r'[ã‚-ã‚“ã‚¢-ãƒ³ä¸€-é¾¯]', line):
                            continue

                        # æ•°å­—ã¨ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆã®æ··åœ¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
                        if re.search(r'\d+[a-zA-Z]+\d+|[a-zA-Z]+\d+[a-zA-Z]+', line):
                            continue
                            
                        # 3. æ„å‘³ã®ã‚ã‚‹æ–‡å­—åˆ—ã®åˆ¤å®š
                        has_japanese = any(0x3000 <= ord(c) <= 0x9FFF for c in line)
                        has_meaningful_ascii = (
                            any(c.isalpha() for c in line) and  # ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆã‚’å«ã‚€
                            sum(1 for c in line if c.isalnum()) > len(line) * 0.4 and  # ã‚ˆã‚Šå³ã—ã„è‹±æ•°å­—ã®æ¯”ç‡
                            len(line) >= 5 and  # æœ€å°é•·ã‚’å¢—åŠ 
                            not re.search(r'[A-Z0-9]{4,}', line)  # å¤§æ–‡å­—ã¨æ•°å­—ã®é€£ç¶šã‚’åˆ¶é™
                        )
                        
                        # URLã‚„ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ã‚ˆã†ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é™¤å¤–
                        if any(pattern in line for pattern in ['http', '://', '.com', '.jp', '#', '@']):
                            continue
                            
                        if has_japanese or has_meaningful_ascii:
                            # 4. ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
                            # é€£ç¶šã™ã‚‹ç©ºç™½ã‚’1ã¤ã«
                            line = ' '.join(line.split())
                            # å‰å¾Œã®è¨˜å·ã‚’é™¤å»
                            line = line.strip('_-=@#$%^&*()[]{}|;:,.<>?/\\')
                            if len(line) > 3:  # å†åº¦é•·ã•ãƒã‚§ãƒƒã‚¯
                                cleaned_lines.append(line)

                    # æœ€ä½æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯
                    if len(''.join(cleaned_lines)) < 5:  # åˆè¨ˆ5æ–‡å­—æœªæº€ã¯é™¤å¤–
                        cleaned_lines = []

                    # ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜
                    cleaned_text = '\n'.join(cleaned_lines)
                    if cleaned_text.strip():
                        ss["text"] = cleaned_text
                    else:
                        ss["text"] = ""
                    
                except UnicodeError as e:
                    print(f"æ–‡å­—ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼ {ss['image_path']}: {str(e)}")
                    ss["text"] = ""

            except Exception as e:
                print(f"OCRã‚¨ãƒ©ãƒ¼ {ss['image_path']}: {str(e)}")
                ss["text"] = ""

        return screenshots

    def analyze_content(self, transcription, screenshots):
        """éŸ³å£°èªè­˜çµæœã¨ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’çµ„ã¿åˆã‚ã›ã¦ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’åˆ†æ"""
        segments = []
        current_segment = []
        current_screenshots = []
        start_time = 0
        segment_duration = 60  # 1åˆ†ã”ã¨ã«ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†å‰²

        sorted_transcription = sorted(transcription, key=lambda x: x['start'])

        for entry in sorted_transcription:
            while screenshots and screenshots[0]["timestamp"] <= entry["end"]:
                current_screenshots.append(screenshots.pop(0))

            current_segment.append(entry)
            
            if (entry['end'] - start_time > segment_duration or
                (len(current_segment) > 1 and
                 self._topic_changed(current_segment[-2]['text'], entry['text']))):
                
                segment_text = ' '.join(item['text'] for item in current_segment)
                
                    segment_info = {
                        'start': start_time,
                        'end': entry['end'],
                        'text': segment_text,
                        'heading': self.generate_heading(segment_text),
                        'summary': self.generate_summary(segment_text),
                        'key_points': self.extract_key_points(segment_text),
                        'screenshots': [{
                            'path': ss['image_path'],
                            'timestamp': ss['timestamp'],
                            'text': ss.get('text', '')
                        } for ss in current_screenshots]
                    }
                    segments.append(segment_info)
                
                start_time = entry['end']
                current_segment = []
                current_screenshots = []

        if current_segment:
            segment_text = ' '.join(item['text'] for item in current_segment)
                segments.append({
                    'start': start_time,
                    'end': current_segment[-1]['end'],
                    'text': segment_text,
                    'heading': self.generate_heading(segment_text),
                    'summary': self.generate_summary(segment_text),
                    'key_points': self.extract_key_points(segment_text),
                    'screenshots': [{
                        'path': ss['image_path'],
                        'timestamp': ss['timestamp'],
                        'text': ss.get('text', '')
                } for ss in current_screenshots + screenshots]
                })

        return segments

    def generate_heading(self, text):
        """è¦‹å‡ºã—ç”Ÿæˆã®å®Ÿè£…"""
        try:
            from transformers import T5Tokenizer, T5ForConditionalGeneration
            tokenizer = T5Tokenizer.from_pretrained("sonoisa/t5-base-japanese")
            model = T5ForConditionalGeneration.from_pretrained("sonoisa/t5-base-japanese")
            
            input_text = f"ã‚¿ã‚¤ãƒˆãƒ«: {text[:500]}"
            input_ids = tokenizer.encode(
                input_text,
                return_tensors="pt",
                max_length=512,
                truncation=True
            )
            
            outputs = model.generate(
                input_ids,
                max_length=30,
                min_length=10,
                num_beams=4,
                temperature=0.7,
                no_repeat_ngram_size=2,
                top_k=50,
                top_p=0.95,
                early_stopping=True
            )
            
            heading = tokenizer.decode(outputs[0], skip_special_tokens=True)
            heading = heading.replace("ã‚¿ã‚¤ãƒˆãƒ«:", "").strip()
            return heading
            
        except Exception as e:
            print(f"è¦‹å‡ºã—ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            words = text[:100].split()
            return ' '.join(words[:5]) + "..."

    def generate_summary(self, text):
        """è¦ç´„ç”Ÿæˆã®å®Ÿè£…"""
        try:
            summarizer = pipeline("summarization",
                                model="ku-nlp/bart-base-japanese",
                                tokenizer="ku-nlp/bart-base-japanese")
            
            text_length = len(text)
            if text_length < 100:
                max_length = 30
                min_length = 10
            else:
                max_length = min(100, text_length // 3)
                min_length = max(30, text_length // 6)
            
            summary = summarizer(
                text[:1000],
                max_length=max_length,
                min_length=min_length,
                no_repeat_ngram_size=3,
                num_beams=4,
                temperature=0.7,
                do_sample=True
            )[0]['summary_text']
            
            return summary.strip()
            
        except Exception as e:
            print(f"è¦ç´„ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            sentences = text.split('ã€‚')[:2]
            return 'ã€‚'.join(sentences) + 'ã€‚'

    def _calculate_similarity(self, text1, text2):
        """2ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆé–“ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—"""
        # æ–‡å­—ãƒ¬ãƒ™ãƒ«ã®n-gramã‚’ä½¿ç”¨ã—ã¦é¡ä¼¼åº¦ã‚’è¨ˆç®—
        def get_ngrams(text, n=3):
            return set(''.join(gram) for gram in zip(*[text[i:] for i in range(n)]))
        
        # ä¸¡æ–¹ã®ãƒ†ã‚­ã‚¹ãƒˆã®n-gramã‚’å–å¾—
        ngrams1 = get_ngrams(text1)
        ngrams2 = get_ngrams(text2)
        
        # Jaccardé¡ä¼¼åº¦ã‚’è¨ˆç®—
        intersection = len(ngrams1 & ngrams2)
        union = len(ngrams1 | ngrams2)
        return intersection / union if union > 0 else 0

    def extract_key_points(self, text):
        """ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæŠ½å‡ºã®æ”¹å–„å®Ÿè£…"""
        try:
            from transformers import T5Tokenizer, T5ForConditionalGeneration
            
            # ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†
            cleaned_text = re.sub(r'[\(\)\[\]ã€Œã€ã€ã€]', '', text)  # æ‹¬å¼§é¡ã‚’å‰Šé™¤
            cleaned_text = re.sub(r'[:ï¼š]', '', cleaned_text)  # ã‚³ãƒ­ãƒ³ã‚’å‰Šé™¤
            cleaned_text = re.sub(r'\s+', ' ', cleaned_text).strip()  # ç©ºç™½ã®æ­£è¦åŒ–
            
            if not cleaned_text:
                return []
            
            tokenizer = T5Tokenizer.from_pretrained("sonoisa/t5-base-japanese")
            model = T5ForConditionalGeneration.from_pretrained("sonoisa/t5-base-japanese")
            
            input_text = f"ä»¥ä¸‹ã®æ–‡ç« ã‹ã‚‰é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’æŠ½å‡ºã—ã¦ãã ã•ã„: {cleaned_text[:500]}"
            input_ids = tokenizer.encode(
                input_text,
                return_tensors="pt",
                max_length=512,
                truncation=True
            )
            
            outputs = model.generate(
                input_ids,
                max_length=150,
                min_length=30,
                num_beams=5,
                temperature=0.6,  # ã‚ˆã‚Šç¢ºå®Ÿãªç”Ÿæˆã®ãŸã‚æ¸©åº¦ã‚’ä¸‹ã’ã‚‹
                no_repeat_ngram_size=3,
                top_k=30,
                top_p=0.92,
                early_stopping=True,
                repetition_penalty=1.2  # ç¹°ã‚Šè¿”ã—ã‚’æŠ‘åˆ¶
            )
            
            key_points_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã®è©³ç´°ãªå¾Œå‡¦ç†
            key_points = []
            seen_points = set()
            
            for point in key_points_text.split('ã€‚'):
                # åŸºæœ¬çš„ãªã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
                point = point.strip()
                point = re.sub(r'(é‡è¦|å¤§äº‹)(\s*ãª)?\s*(ãƒã‚¤ãƒ³ãƒˆ|ç‚¹)\s*[:ï¼š]?', '', point)  # æ¥é ­è¾ã®é™¤å»
                point = re.sub(r'[ã€Œã€ã€ã€ï¼ˆï¼‰\(\)\[\]\{\}]', '', point)  # æ‹¬å¼§é¡ã®é™¤å»
                point = re.sub(r'[:ï¼šã€‚ã€]$', '', point)  # æœ«å°¾ã®åŒºåˆ‡ã‚Šæ–‡å­—ã‚’é™¤å»
                point = point.strip()
                
                # æ„å‘³ã®ã‚ã‚‹å†…å®¹ã‹ãƒã‚§ãƒƒã‚¯
                if not point or len(point) < 8:  # æœ€å°é•·ã•ã‚’å¢—åŠ 
                    continue
                
                # æ—¥æœ¬èªæ–‡å­—ã‚’å«ã‚€ã‹ãƒã‚§ãƒƒã‚¯
                if not re.search(r'[ã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¯]', point):
                    continue
                    
                # è¨˜å·ã®ã¿ã®è¡Œã‚’é™¤å¤–
                if re.match(r'^[\s\W]+$', point):
                    continue
                    
                # çœç•¥è¨˜å·ã§çµ‚ã‚ã‚‹ä¸å®Œå…¨ãªæ–‡ã‚’é™¤å¤–
                if point.endswith(('...', 'â€¦', 'â†’')):
                    continue
                    
                # é‡è¤‡ã‚„é¡ä¼¼ã®ãƒã‚§ãƒƒã‚¯
                is_duplicate = any(
                    self._calculate_similarity(point, existing) > 0.6  # é¡ä¼¼åº¦ã®é–¾å€¤ã‚’èª¿æ•´
                    for existing in seen_points
                )
                
                if not is_duplicate:
                    key_points.append(point)
                    seen_points.add(point)
            
            return key_points if key_points else [cleaned_text[:100] + "..."]
            
        except Exception as e:
            print(f"ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}")
            return [text[:100] + "..."]

    def generate_html_report(self, results):
        """HTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        try:
            # CSSå®šç¾©
            css = '''
                body {
                    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Noto Sans JP", sans-serif;
                    line-height: 1.6;
                    margin: 0;
                    padding: 0;
                    background: #ffffff;
                }
                .container {
                    max-width: 900px;
                    margin: 0 auto;
                    padding: 2rem;
                }
                h1 { font-size: 2.5em; font-weight: 700; margin-bottom: 1em; color: #333; }
                h2 { font-size: 1.8em; font-weight: 600; margin: 1em 0 0.5em; color: #333; }
                h3 { font-size: 1.2em; font-weight: 600; color: #333; }
                .segment {
                    margin-bottom: 2.5em;
                    padding: 1.5em;
                    border: 1px solid #e1e4e8;
                    border-radius: 6px;
                    background: #fff;
                }
                .segment-header {
                    margin-bottom: 1em;
                    padding-bottom: 0.5em;
                    border-bottom: 1px solid #e1e4e8;
                }
                .segment-time { color: #666; font-size: 0.9em; }
                .summary-section {
                    background: #f6f8fa;
                    padding: 1em;
                    border-radius: 4px;
                    margin: 1em 0;
                }
                .key-points {
                    list-style-type: none;
                    padding-left: 0;
                }
                .key-points li {
                    position: relative;
                    padding-left: 1.5em;
                    margin-bottom: 0.5em;
                }
                .key-points li:before {
                    content: "â€¢";
                    position: absolute;
                    left: 0.5em;
                    color: #0366d6;
                }
                .screenshot-container {
                    margin: 1.5em 0;
                    border: 1px solid #e1e4e8;
                    border-radius: 4px;
                    overflow: hidden;
                }
                .screenshot {
                    max-width: 100%;
                    display: block;
                }
                .timestamp {
                    color: #666;
                    font-size: 0.9em;
                    margin: 0.5em 1em;
                }
                .ocr-text {
                    font-family: "Noto Sans JP", "Noto Sans CJK JP", monospace;
                    font-size: 0.95em;
                    line-height: 1.8;
                    background: #f6f8fa;
                    color: #24292e;
                    padding: 1em;
                    margin: 1em;
                    border-radius: 4px;
                    white-space: pre-line;
                    border-left: 3px solid #0366d6;
                }
                .metadata {
                    margin-top: 3em;
                    padding-top: 1em;
                    border-top: 1px solid #e1e4e8;
                    color: #666;
                    font-size: 0.9em;
                }
            '''

            # HTMLã®æ§‹ç¯‰
            html_parts = [
                "<!DOCTYPE html>",
                '<html lang="ja">',
                "<head>",
                '<meta charset="UTF-8">',
                '<meta http-equiv="Content-Type" content="text/html; charset=utf-8">',
                '<meta name="viewport" content="width=device-width, initial-scale=1.0">',
                "<title>å‹•ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„è¦ç´„</title>",
                f"<style>{css}</style>",
                "</head>",
                "<body>",
                "<div class='container'>",
                "<h1>ğŸ“ å‹•ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„è¦ç´„</h1>",
                f"<p>ãƒ•ã‚¡ã‚¤ãƒ«å: {results.get('video_file', 'ä¸æ˜')}</p>",
                "<div class='content'>"
            ]

            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®å‡¦ç†
            for segment in results.get("segments", []):
                # æ™‚é–“ã®æ–‡å­—åˆ—åŒ–
                start_time = str(datetime.timedelta(seconds=int(segment["start"])))
                end_time = str(datetime.timedelta(seconds=int(segment["end"])))

                # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®å†…å®¹ã‚’è¿½åŠ 
                html_parts.extend([
                    "<div class='segment'>",
                    "<div class='segment-header'>",
                    f"<div class='segment-time'>{start_time} - {end_time}</div>",
                    f"<h2>{html.escape(segment['heading'])}</h2>",
                    "</div>",
                    "<div class='summary-section'>",
                    "<h3>ğŸ“ è¦ç´„</h3>",
                    f"<p>{html.escape(segment['summary'])}</p>",
                    "</div>",
                    "<h3>ğŸ¯ ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ</h3>",
                    "<ul class='key-points'>"
                ])

                # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã®è¿½åŠ 
                for point in segment['key_points']:
                    html_parts.append(f"<li>{html.escape(point)}</li>")

                html_parts.append("</ul>")

                # ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã¨OCRãƒ†ã‚­ã‚¹ãƒˆã®å‡¦ç†
                for ss in segment.get('screenshots', []):
                    timestamp = str(datetime.timedelta(seconds=int(ss['timestamp'])))
                    # ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®ãƒ‘ã‚¹ã‚’ç›¸å¯¾ãƒ‘ã‚¹ã«å¤‰æ›
                    relative_path = os.path.relpath(ss['path'], self.output_dir)
                    html_parts.extend([
                        "<div class='screenshot-container'>",
                        f"<img src='{relative_path}' alt='Screenshot' class='screenshot'>",
                        f"<div class='timestamp'>ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: {timestamp}</div>"
                    ])

                    # OCRãƒ†ã‚­ã‚¹ãƒˆã®å‡¦ç†ï¼ˆæ–‡å­—åŒ–ã‘å¯¾ç­–å¼·åŒ–ç‰ˆï¼‰
                    ocr_text = ss.get('text', '').strip()
                    if ocr_text:
                        try:
                            # æ–‡å­—ã‚³ãƒ¼ãƒ‰ã®æ­£è¦åŒ–
                            ocr_text = unicodedata.normalize('NFKC', ocr_text)
                            # åˆ¶å¾¡æ–‡å­—ã®é™¤å»ã¨ç©ºç™½ã®æ­£è¦åŒ–
                            ocr_text = ''.join(char for char in ocr_text if ord(char) >= 32 or char == '\n')
                            ocr_text = re.sub(r'\s+', ' ', ocr_text)
                            # HTMLã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã¨æ”¹è¡Œå‡¦ç†
                            ocr_text = html.escape(ocr_text).replace('\n', '<br>')
                            
                            if ocr_text.strip():
                                html_parts.append(
                                    '<div class="ocr-text">'
                                    '<span style="color: #666;">ğŸ“„ æ¤œå‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ:</span><br>'
                                    f'{ocr_text}'
                                    '</div>'
                                )
                        except Exception as e:
                            print(f"OCRãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")

                    html_parts.append("</div>")  # screenshot-containerçµ‚äº†

                html_parts.append("</div>")  # segmentçµ‚äº†

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ 
            metadata = results.get("metadata", {})
            duration = str(datetime.timedelta(seconds=int(metadata.get("video_duration", 0))))
            html_parts.extend([
                "<div class='metadata'>",
                f"<p>å‡¦ç†æ—¥æ™‚: {metadata.get('processed_at', 'ä¸æ˜')}</p>",
                f"<p>å‹•ç”»æ™‚é–“: {duration}</p>",
                f"<p>ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°: {metadata.get('segment_count', 0)}</p>",
                "</div>",
                "</div>",  # contentçµ‚äº†
                "</div>",  # containerçµ‚äº†
                "</body>",
                "</html>"
            ])

            # HTMLãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ï¼ˆself.output_dirã‚’ä½¿ç”¨ï¼‰
            os.makedirs(self.output_dir, exist_ok=True)
            html_path = os.path.join(self.output_dir, "report.html")
            
            # HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’BOMä»˜ãUTF-8ã§ä¿å­˜
            with open(html_path, "wb") as f:
                content = "\n".join(html_parts)
                # BOMã‚’è¿½åŠ ã—ã¦UTF-8ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
                f.write(b'\xef\xbb\xbf')
                f.write(content.encode('utf-8', errors='replace'))

            print(f"HTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {html_path}")
            return html_path

        except Exception as e:
            import traceback
            print(f"HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            print(f"ã‚¨ãƒ©ãƒ¼ã®è©³ç´°:\n{traceback.format_exc()}")
            return None

    def save_results(self, result):
        """çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        try:
            # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
            os.makedirs(self.output_dir, exist_ok=True)
            
            # çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
            output_json = os.path.join(self.output_dir, 'transcription_result.json')
            with open(output_json, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            # HTMLãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
            html_path = self.generate_html_report(result)
            
            print(f"çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ:")
            print(f"- JSON: {output_json}")
                print(f"- HTML: {html_path}")
            
        except Exception as e:
            import traceback
            print(f"çµæœã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            print(f"ã‚¨ãƒ©ãƒ¼ã®è©³ç´°:\n{traceback.format_exc()}")

    def _generate_html_report(self, result):
        """HTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        html_template = """
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="utf-8">
            <title>å‹•ç”»æ›¸ãèµ·ã“ã—ãƒ¬ãƒãƒ¼ãƒˆ</title>
            <style>
                body {
                    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
                    margin: 20px;
                    line-height: 1.6;
                }
                .section {
                    margin-bottom: 30px;
                    padding: 20px;
                    background: #f8f9fa;
                    border-radius: 8px;
                }
                .timestamp {
                    color: #666;
                    font-size: 0.9em;
                }
                .screenshot {
                    max-width: 100%;
                    height: auto;
                    margin: 10px 0;
                    border-radius: 4px;
                    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
                }
                .transcription {
                    margin: 10px 0;
                    padding: 10px;
                    background: white;
                    border-radius: 4px;
                }
                .screenshot-section {
                    margin-bottom: 20px;
                    padding: 15px;
                    background: white;
                    border-radius: 4px;
                    box-shadow: 0 1px 3px rgba(0,0,0,0.1);
                }
                h1, h2, h3 {
                    color: #333;
                }
                .text {
                    margin: 10px 0;
                    line-height: 1.6;
                }
            </style>
        </head>
        <body>
            <h1>å‹•ç”»æ›¸ãèµ·ã“ã—ãƒ¬ãƒãƒ¼ãƒˆ</h1>
            <h2>ãƒ•ã‚¡ã‚¤ãƒ«: {video_file}</h2>
            
            <div class="section">
                <h3>ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ</h3>
                {screenshots_html}
            </div>
            
            <div class="section">
                <h3>æ›¸ãèµ·ã“ã—</h3>
                {transcription_html}
            </div>
        </body>
        </html>
        """
        
        # ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®HTMLç”Ÿæˆ
        screenshots_html = ""
        for ss in result.get('screenshots', []):
            screenshots_html += f"""
            <div class="screenshot-section">
                <p class="timestamp">æ™‚é–“: {ss['timestamp']}ç§’</p>
                <img class="screenshot" src="{os.path.basename(ss['image_path'])}" alt="Screenshot">
                <p class="text">{html.escape(ss.get('text', ''))}</p>
            </div>
            """
        
        # æ›¸ãèµ·ã“ã—ã®HTMLç”Ÿæˆ
        transcription_html = ""
        for entry in result.get('transcription', []):
            transcription_html += f"""
            <div class="transcription">
                <span class="timestamp">[{entry['start']}s - {entry['end']}s]</span>
                <span class="text">{html.escape(entry['text'])}</span>
            </div>
            """
        
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«å€¤ã‚’æŒ¿å…¥
        html_content = html_template.format(
            video_file=html.escape(result.get('video_file', 'ä¸æ˜')),
            screenshots_html=screenshots_html,
            transcription_html=transcription_html
        )
        
        return html_content

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python video_processor.py <å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹>")
        sys.exit(1)
        
    video_path = sys.argv[1]
    processor = VideoProcessor()
    result = processor.process_video(video_path)
    
    if result:
        processor.save_results(result)
        print("å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ")
    else:
        print("å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
